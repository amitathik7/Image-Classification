{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fadcc4-f15f-4e17-8425-5b40d3dde69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently modifying model layers\n",
    "# Validation Accuracy Goal: 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7ca0e6-7181-4d08-81f1-358d25cd94f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading training images, testing images, and image labels from CIFAR-10 folder\n",
    "\n",
    "import os\n",
    "\n",
    "training_path = 'CIFAR-10 Images/Training/'\n",
    "testing_path = 'CIFAR-10 Images/Testing'\n",
    "label_path = 'CIFAR-10 Images/batches.meta'\n",
    "\n",
    "training_data = []\n",
    "training_label_data = []\n",
    "testing_data = []\n",
    "testing_label_data = []\n",
    "\n",
    "def unpickle_file(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as tmp:\n",
    "        dict = pickle.load(tmp, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "label_names = unpickle_file(label_path)[b'label_names']\n",
    "\n",
    "def process_files(folder_path, data_container, label_container):\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            dict = unpickle_file(file_path)\n",
    "            data, labels = dict[b'data'], dict[b'labels']\n",
    "            data_container.append(data)\n",
    "            label_container.append(labels)\n",
    "\n",
    "process_files(training_path, training_data, training_label_data)\n",
    "process_files(testing_path, testing_data, testing_label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e00b82-0a76-44b7-b26d-b8b8e315308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the image data from (3072,) to (32, 32, 3)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def reshape_image(image_1d_array):\n",
    "    # Setting up an empty 3D array of zeros to put in data\n",
    "    image_reshaped = np.zeros((32, 32, 3), dtype=np.uint8)\n",
    "\n",
    "    # Red\n",
    "    image_reshaped[:, :, 0] = image_1d_array[:1024].reshape(32, 32)\n",
    "    # Green\n",
    "    image_reshaped[:, :, 1] = image_1d_array[1024:2048].reshape(32, 32)\n",
    "    # Blue\n",
    "    image_reshaped[:, :, 2] = image_1d_array[2048:].reshape(32, 32)\n",
    "\n",
    "    return image_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa912ae7-c189-427a-850d-0136faca1e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "def create_cnn_model():\n",
    "    # model = models.Sequential([\n",
    "    #     # layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    #     # Can be replace with these 2 lines but gives a warning\n",
    "    #     # ============================================= #\n",
    "    #     layers.Input(shape=(32, 32, 3)),\n",
    "    #     layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    #     # ============================================= #\n",
    "    #     layers.MaxPooling2D((2, 2)),\n",
    "    #     layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    #     layers.MaxPooling2D((2, 2)),\n",
    "    #     layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    #     layers.Flatten(),\n",
    "    #     layers.Dense(64, activation='relu'),\n",
    "    #     layers.Dense(10)\n",
    "    # ])\n",
    "    \n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(32, 32, 3)),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        layers.AveragePooling2D((2, 2)),\n",
    "        layers.RandomContrast((0, 1)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.AveragePooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10)\n",
    "    ])\n",
    "    \n",
    "    # model = models.Sequential([\n",
    "    #     layers.Input(shape=(32, 32, 3)),\n",
    "    #     layers.Conv2D(16, (3, 3), activation='relu'),\n",
    "    #     layers.MaxPooling2D((3, 3)),\n",
    "    #     layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    #     layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    #     layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    #     layers.Flatten(),\n",
    "    #     layers.Dense(64, activation='relu'),\n",
    "    #     layers.Dense(10)\n",
    "    # ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                 loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0acd41b-bc54-4fde-b161-915deed06e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = []\n",
    "all_labels = []\n",
    "\n",
    "for batch in training_data:\n",
    "    for img in batch:\n",
    "        reshaped_image = reshape_image(img)\n",
    "        all_images.append(reshaped_image)\n",
    "\n",
    "for batch in training_label_data:\n",
    "    for label in batch:\n",
    "        all_labels.append(label)\n",
    "\n",
    "x_train = np.array(all_images)\n",
    "y_train = np.array(all_labels)\n",
    "\n",
    "x_val = np.array([reshape_image(img) for img in testing_data[0]])\n",
    "y_val = np.array(testing_label_data[0])\n",
    "\n",
    "model = create_cnn_model()\n",
    "model.fit(x_train, y_train, epochs=15, batch_size=128, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cf332a-c70f-462d-a5d8-6668cfca0f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just some code to display some of the pictures\n",
    "# Not required so I've left it on the bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fcdcb5-bb73-4a9d-97df-402d241ca898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "graph_size = 10\n",
    "\n",
    "def show_images(images, labels, class_names, width):\n",
    "    plt.figure(figsize=(graph_size, graph_size))\n",
    "    for i in range(width * width):  # Display first 25 images\n",
    "        plt.subplot(width, width, i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[i].reshape(32, 32, 3), cmap=plt.cm.binary)  # Reshape and display\n",
    "        if width <= 8:\n",
    "            plt.xlabel(class_names[labels[i]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82971979-184d-4108-9587-94b2b33a4806",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = training_data[0]\n",
    "images = images.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "\n",
    "show_images(images, labels, label_names, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
